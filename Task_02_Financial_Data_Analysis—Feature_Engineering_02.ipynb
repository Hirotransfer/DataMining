{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [特征工程之特征选择：](https://www.cnblogs.com/wkslearner/p/8933685.html)\n",
    "\n",
    "- **特征工程（Feature Engineering）**\n",
    "    - 什么是**特征工程**，理解其**含义**\n",
    "    - 对**特征**进行**衍生** 和 **选择**\n",
    "        - **特征衍生**：\n",
    "        - **特征选择**："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **特征工程**是通过对原始数据的处理和加工，将原始数据**属性**通过处理转换为数据**特征**的过程，属性是**数据本身具有的维度**，特征是数据中所呈现出来的某一种重要的特性，通常是通过属性的计算，组合或转换得到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 特征衍生 和 特征选择\n",
    "\n",
    "> 在建模过程中，我们通常会遇到一些问题，现有特征的显著性不高或者特定算法的需要，我们需要从现有数据中构造一些特征，有时又可能因为特征过多，而需要降维处理，一般的方法是从众多特征中提取出特征的共性，然后进行建模。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 特征衍生\n",
    "\n",
    "> **特征衍生**一般是对原有的特征进行转换，计算以及组合而产生的新的特征\n",
    "\n",
    "> **单一变量的基础转换**\n",
    "> **变量通过添加时间维度进行衍生**\n",
    "> **多变量的运算**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 特征提取\n",
    "\n",
    "> **特征提取**是通过从原始特征中找出子有效的特征，其目的是降低数据冗余，减少模型计算，发现根由价值的特征\n",
    "\n",
    "> **线性特征提取**\n",
    "\n",
    "> **非线性特征提取**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 特征选择\n",
    "\n",
    "> **特征选择**的一般过程为：先从特征全集中产生出一个特征子集，筛选过程采用某种评价标准，将符合标准的特征筛选出来，同时对筛选出来的特征进行有效性验证。\n",
    "\n",
    "> 产生的子集一般是一个搜索的过程，搜索空间中的每个状态就是一个特征子集，搜索算法分为完全搜索，启发式搜索和随机搜索。\n",
    "\n",
    "> 特征选择的过程可分为：**IV值**，**RF随机森林**，**特征过滤**，**Wrapper**，**Ebedded**等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务说明：\n",
    "\n",
    "- 利用 **金融数据** 来预测贷款用户是否会逾期\n",
    "- 其中，**“status”** 是结果标签：**0** 表示未逾期，**1** 表示逾期"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务要求：\n",
    "\n",
    "> **特征选择Feature Selection**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务实现：（2 Days）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [特征选择Feature Selection：](https://blog.csdn.net/zhangyunpeng0922/article/details/84591046?from=groupmessage&isappinstalled=0)\n",
    "\n",
    "> **利用IV值进行特征选择**\n",
    "\n",
    "> **利用Random Forests随机森林进行特征选择**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 当[数据预处理](https://blog.csdn.net/zhangyunpeng0922/article/details/84591046?from=groupmessage&isappinstalled=0)完成后，我们需要选择有意义的特征输入机器学习的算法和模型进行训练。\n",
    "\n",
    "> ### 特征是否发散\n",
    "\n",
    "> ### 特征 与 目标的相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 利用IV值进行特征选择(用[IV值](https://blog.csdn.net/a786150017/article/details/84573202)衡量变量预测能力)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ###  [WOE(Weight of Evidence)的计算](https://blog.csdn.net/kevin7658/article/details/50780391/)\n",
    "\n",
    "> **WOEi = ln(pyi/pni) = ln(#yi/#yt)/(#ni/#nt)**\n",
    "\n",
    "> **等价于**\n",
    "\n",
    "> **WOEi = ln(pyi/pni) = ln(#yi/#yt)/(#ni/#nt) = ln(#yi/#ni)/(#yt/#nt)**\n",
    "\n",
    ">**WOE表示的是：“当前分组中响应客户占所有响应客户的比例”和“当前分组中没有响应的客户占所有没有响应的客户的比例”的差异**\n",
    "\n",
    "> ###  IV的计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### IVi = (pyi - pni)*WOEi\n",
    "\n",
    "> ### IV即对总的分组个数 IVi求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset/data.csv') # 文件的读取\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# 载入特征\n",
    "with open('feature.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "# 提取标签\n",
    "y = data.status\n",
    "\n",
    "# 划分训练集测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能评估\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# 定义模型指标\n",
    "def model_metrics(clf, X_train, X_test, y_train, y_test):\n",
    "    # 预测\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    y_train_proba = clf.predict_proba(X_train)[:,1]\n",
    "    y_test_proba = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # 准确率Accuracy\n",
    "    print('[准确率]', end = ' ')\n",
    "    print('训练集：', '%.4f'%accuracy_score(y_train, y_train_pred), end = ' ')\n",
    "    print('测试集：', '%.4f'%accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # AUC取值\n",
    "    print('[auc值]', end = ' ')\n",
    "    print('训练集：', '%.4f'%roc_auc_score(y_train, y_train_proba), end = ' ')\n",
    "    print('测试集：', '%.4f'%roc_auc_score(y_test, y_test_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 利用IV值进行特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "# WOE的计算\n",
    "def woe(X, y, event=1):  \n",
    "    res_woe = []\n",
    "    iv_dict = {}\n",
    "    for feature in X.columns:\n",
    "        x = X[feature].values\n",
    "        # 1) 连续特征离散化\n",
    "        if type_of_target(x) == 'continuous':\n",
    "            x = discrete(x)\n",
    "        # 2) 计算该特征的woe和iv\n",
    "        woe_dict, iv = woe_single_x(x, y, feature, event)\n",
    "        iv_dict[feature] = iv\n",
    "        res_woe.append(woe_dict) \n",
    "        \n",
    "    return iv_dict\n",
    "\n",
    "# 离散化处理        \n",
    "def discrete(x):\n",
    "    # 使用5等分离散化特征\n",
    "    res = np.zeros(x.shape)\n",
    "    for i in range(5):\n",
    "        point1 = stats.scoreatpercentile(x, i * 20)\n",
    "        point2 = stats.scoreatpercentile(x, (i + 1) * 20)\n",
    "        x1 = x[np.where((x >= point1) & (x <= point2))]\n",
    "        mask = np.in1d(x, x1)\n",
    "        res[mask] = i + 1    # 将[i, i+1]块内的值标记成i+1\n",
    "    return res\n",
    "\n",
    "def woe_single_x(x, y, feature,event = 1):\n",
    "    # event代表预测正例的标签\n",
    "    event_total = sum(y == event)\n",
    "    non_event_total = y.shape[-1] - event_total\n",
    "    \n",
    "    iv = 0\n",
    "    woe_dict = {}\n",
    "    for x1 in set(x):    # 遍历各个块\n",
    "        y1 = y.reindex(np.where(x == x1)[0])\n",
    "        event_count = sum(y1 == event)\n",
    "        non_event_count = y1.shape[-1] - event_count\n",
    "        rate_event = event_count / event_total    \n",
    "        rate_non_event = non_event_count / non_event_total\n",
    "        \n",
    "        if rate_event == 0:\n",
    "            rate_event = 0.0001\n",
    "            # woei = -20\n",
    "        elif rate_non_event == 0:\n",
    "            rate_non_event = 0.0001\n",
    "            # woei = 20\n",
    "        woei = math.log(rate_event / rate_non_event)\n",
    "        woe_dict[x1] = woei\n",
    "        iv += (rate_event - rate_non_event) * woei\n",
    "    return woe_dict, iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "iv_dict = woe(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('historical_trans_amount', 2.6975301004625365),\n",
       " ('trans_amount_3_month', 2.5633548887586746),\n",
       " ('pawns_auctions_trusts_consume_last_6_month', 2.343990314630991),\n",
       " ('repayment_capability', 2.31685232254565),\n",
       " ('first_transaction_day', 2.10946672748192),\n",
       " ('abs', 2.048054369415617),\n",
       " ('consfin_avg_limit', 1.8005797778063934),\n",
       " ('consume_mini_time_last_1_month', 1.4570522032774857),\n",
       " ('loans_avg_limit', 1.3508993179510962),\n",
       " ('max_cumulative_consume_later_1_month', 1.2961861663340406),\n",
       " ('historical_trans_day', 1.0794587869439352),\n",
       " ('pawns_auctions_trusts_consume_last_1_month', 0.9637730486540506),\n",
       " ('consfin_credit_limit', 0.829726960824839),\n",
       " ('loans_score', 0.8035125155540374),\n",
       " ('loans_latest_day', 0.7177168342745962),\n",
       " ('avg_price_last_12_month', 0.6395438326722515),\n",
       " ('history_suc_fee', 0.6322293100618446),\n",
       " ('apply_score', 0.5592084043426475),\n",
       " ('latest_query_day', 0.5017485264222311),\n",
       " ('consfin_max_limit', 0.483273473979316),\n",
       " ('loans_long_time', 0.4592776814323623),\n",
       " ('take_amount_in_later_12_month_highest', 0.44551742754223506),\n",
       " ('loans_settle_count', 0.4411031020652967),\n",
       " ('history_fail_fee', 0.42562735786381),\n",
       " ('loans_count', 0.4001622824946951),\n",
       " ('trans_days_interval_filter', 0.3985310761632303),\n",
       " ('loans_max_limit', 0.37263143500206936),\n",
       " ('consume_top_time_last_6_month', 0.349022605284868),\n",
       " ('trans_top_time_last_6_month', 0.34814710882405003),\n",
       " ('number_of_trans_from_2011', 0.3424276547627279),\n",
       " ('latest_six_month_loan', 0.33895099903184556),\n",
       " ('trans_days_interval', 0.33857176437512965),\n",
       " ('trans_day_last_12_month', 0.33503487199625653),\n",
       " ('latest_query_time_day', 0.3201102732169854),\n",
       " ('latest_six_month_apply', 0.3167512025877789),\n",
       " ('loans_credit_limit', 0.30559284801552467),\n",
       " ('apply_credibility', 0.29830373382617764),\n",
       " ('loans_latest_time_day', 0.29396227865604874),\n",
       " ('loans_org_count_behavior', 0.29367166639534587),\n",
       " ('query_sum_count', 0.2913852759631131),\n",
       " ('query_org_count', 0.284857522455637),\n",
       " ('transd_mcc', 0.2800425079015167),\n",
       " ('latest_three_month_apply', 0.2774919546093642),\n",
       " ('latest_one_month_fail', 0.2774414710765742),\n",
       " ('latest_one_month_apply', 0.2764096502289849),\n",
       " ('loans_cash_count', 0.26643055859379),\n",
       " ('loans_org_count_current', 0.26643055859379),\n",
       " ('consume_top_time_last_1_month', 0.26099550987334463),\n",
       " ('trans_top_time_last_1_month', 0.2609160030161336),\n",
       " ('first_transaction_time_day', 0.2590484920303237),\n",
       " ('max_consume_count_later_6_month', 0.25742951507849315),\n",
       " ('trans_fail_top_count_enum_last_12_month', 0.25348533997989),\n",
       " ('loans_product_count', 0.24963018741221274),\n",
       " ('query_finance_count', 0.24719289152922377),\n",
       " ('latest_one_month_suc', 0.24568078054601297),\n",
       " ('latest_three_month_loan', 0.24538973397713515),\n",
       " ('loans_credibility_limit', 0.24334672976386584),\n",
       " ('consfin_credibility', 0.23774476750037496),\n",
       " ('query_cash_count', 0.23553151956888524),\n",
       " ('loans_credibility_behavior', 0.23537823783293418),\n",
       " ('loans_latest_time_month', 0.23536009610676906),\n",
       " ('loans_overdue_count', 0.23419785770655852),\n",
       " ('trans_fail_top_count_enum_last_6_month', 0.23290439952486663),\n",
       " ('cross_consume_count_last_1_month', 0.23101341148565974),\n",
       " ('consfin_product_count', 0.2299132438170062),\n",
       " ('trans_fail_top_count_enum_last_1_month', 0.2292932379880621),\n",
       " ('latest_query_time_month', 0.22281703262580477),\n",
       " ('avg_consume_less_12_valid_month', 0.22239702810015521),\n",
       " ('consfin_org_count_behavior', 0.22010497210894556),\n",
       " ('consfin_org_count_current', 0.22010497210894556),\n",
       " ('jewelry_consume_count_last_6_month', 0.21790403970323896),\n",
       " ('reg_preference_for_trad', 0.2177870321526657),\n",
       " ('first_transaction_time_month', 0.21771183020755758),\n",
       " ('trans_amount_increase_rate_lately', 0.20702655677398674),\n",
       " ('latest_one_month_loan', 0.20660231377938928),\n",
       " ('regional_mobility', 0.20654433409120623),\n",
       " ('first_transaction_time_year', 0.2046103090844746),\n",
       " ('trans_activity_day', 0.2027036558499224),\n",
       " ('trans_activity_month', 0.20061987700620626),\n",
       " ('railway_consume_count_last_12_month', 0.2003683041664725),\n",
       " ('loans_latest_time_year', 0.19963733017168203),\n",
       " ('middle_volume_percent', 0.1987889286921986),\n",
       " ('top_trans_count_last_1_month', 0.1982985665309038),\n",
       " ('latest_query_time_year', 0.19785800765281902),\n",
       " ('student_feature', 0.1973961955679536),\n",
       " ('rank_trad_1_month', 0.19690523890879305),\n",
       " ('is_high_user', 0.19615128275454694)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv = sorted(iv_dict.items(), key = lambda x:x[1],reverse = True)\n",
    "iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 模型选择(使用网格搜索)\n",
    "\n",
    "> ### 利用RF随机森林进行特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "袋外分数： 0.737000300571085\n",
      "[准确率] 训练集： 0.9826 测试集： 0.7737\n",
      "[auc值] 训练集： 0.9997 测试集： 0.7088\n"
     ]
    }
   ],
   "source": [
    "# 观察默认参数的性能\n",
    "rf0 = RandomForestClassifier(oob_score=True, random_state=2333)\n",
    "rf0.fit(X_train, y_train)\n",
    "print('袋外分数：', rf0.oob_score_)\n",
    "model_metrics(rf0, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 180}, 0.7855386529283339)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网格法调参\n",
    "param_test = {'n_estimators':range(20,200,20)}\n",
    "gsearch = GridSearchCV(estimator = RandomForestClassifier(n_estimators=120, max_depth=9, min_samples_split=50, \n",
    "                                                          min_samples_leaf=20, max_features = 9,random_state=2333), \n",
    "                       param_grid = param_test, scoring='roc_auc', cv=5)\n",
    "\n",
    "gsearch.fit(X_train, y_train)\n",
    "gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "袋外分数： 0.7835888187556357\n",
      "[准确率] 训练集： 0.8118 测试集： 0.7940\n",
      "[auc值] 训练集： 0.8952 测试集： 0.7883\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, max_depth=9, min_samples_split=50,\n",
    "                            min_samples_leaf=20, max_features = 9,oob_score=True, random_state=2333)\n",
    "rf.fit(X_train, y_train)\n",
    "print('袋外分数：', rf.oob_score_)\n",
    "model_metrics(rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 平均不纯度减少(基于Gini系数的计算)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "feature_impotance1 = sorted(zip(map(lambda x: '%.4f'%x, rf.feature_importances_), list(X_train.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.1312', 'trans_fail_top_count_enum_last_1_month'),\n",
       " ('0.0810', 'loans_score'),\n",
       " ('0.0773', 'history_fail_fee'),\n",
       " ('0.0621', 'apply_score'),\n",
       " ('0.0570', 'latest_one_month_fail'),\n",
       " ('0.0427', 'loans_overdue_count'),\n",
       " ('0.0311', 'trans_fail_top_count_enum_last_12_month'),\n",
       " ('0.0232', 'trans_fail_top_count_enum_last_6_month'),\n",
       " ('0.0208', 'trans_day_last_12_month'),\n",
       " ('0.0190', 'max_cumulative_consume_later_1_month')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_impotance1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 平均精确率减少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "scores = defaultdict(list)\n",
    "rs = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "for train_idx, test_idx in rs.split(X_train):\n",
    "    x_train, x_test = X_train.values[train_idx], X_train.values[test_idx]\n",
    "    Y_train, Y_test = y_train.values[train_idx], y_train.values[test_idx]\n",
    "    r = rf.fit(x_train, Y_train)\n",
    "    acc = accuracy_score(Y_test, rf.predict(x_test))\n",
    "    for i in range(x_train.shape[1]):\n",
    "        X_t = x_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = accuracy_score(Y_test, rf.predict(X_t))\n",
    "        scores[X_train.columns[i]].append((acc - shuff_acc) / acc)\n",
    "        \n",
    "feature_impotance2=sorted([('%.4f'%np.mean(score), feat) for feat, score in scores.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.0171', 'trans_fail_top_count_enum_last_1_month'),\n",
       " ('0.0164', 'history_fail_fee'),\n",
       " ('0.0099', 'latest_one_month_fail'),\n",
       " ('0.0072', 'loans_overdue_count'),\n",
       " ('0.0069', 'loans_score'),\n",
       " ('0.0069', 'apply_score'),\n",
       " ('0.0038', 'trans_fail_top_count_enum_last_6_month'),\n",
       " ('0.0033', 'trans_top_time_last_1_month'),\n",
       " ('0.0033', 'trans_day_last_12_month'),\n",
       " ('0.0020', 'latest_one_month_suc')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_impotance2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 选择重要特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('0.0048', 'number_of_trans_from_2011'),\n",
       " ('0.0003', 'latest_three_month_apply'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_impotance1[50], feature_impotance2[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional_mobility 0.20654433409120623\n",
      "student_feature 0.1973961955679536\n",
      "is_high_user 0.19615128275454694\n",
      "avg_consume_less_12_valid_month 0.22239702810015521\n",
      "first_transaction_time_year 0.2046103090844746\n",
      "first_transaction_time_month 0.21771183020755758\n",
      "latest_query_time_year 0.19785800765281902\n",
      "latest_query_time_month 0.22281703262580477\n",
      "latest_query_time_day 0.3201102732169854\n",
      "loans_latest_time_year 0.19963733017168203\n",
      "loans_latest_time_month 0.23536009610676906\n",
      "number_of_trans_from_2011 0.3424276547627279\n",
      "consume_top_time_last_6_month 0.349022605284868\n",
      "cross_consume_count_last_1_month 0.23101341148565974\n",
      "railway_consume_count_last_12_month 0.2003683041664725\n",
      "jewelry_consume_count_last_6_month 0.21790403970323896\n",
      "query_org_count 0.284857522455637\n",
      "query_cash_count 0.23553151956888524\n",
      "query_sum_count 0.2913852759631131\n",
      "latest_one_month_apply 0.2764096502289849\n",
      "latest_six_month_apply 0.3167512025877789\n",
      "loans_credibility_behavior 0.23537823783293418\n",
      "loans_cash_count 0.26643055859379\n",
      "latest_one_month_loan 0.20660231377938928\n",
      "loans_credibility_limit 0.24334672976386584\n",
      "loans_product_count 0.24963018741221274\n",
      "consfin_credibility 0.23774476750037496\n",
      "consfin_org_count_current 0.22010497210894556\n"
     ]
    }
   ],
   "source": [
    "useless = []\n",
    "for feature in X_train.columns:\n",
    "    if feature in [t[1] for t in feature_impotance1[50:]] and feature in [t[1] for t in feature_impotance2[40:]]:\n",
    "        useless.append(feature)\n",
    "        print(feature, iv_dict[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(useless, axis = 1, inplace = True)\n",
    "X_test.drop(useless, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "袋外分数： 0.7832882476705741\n",
      "[准确率] 训练集： 0.8179 测试集： 0.7947\n",
      "[auc值] 训练集： 0.8971 测试集： 0.7927\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, max_depth=9, min_samples_split=50,\n",
    "                            min_samples_leaf=20, max_features = 9,oob_score=True, random_state=2333)\n",
    "rf.fit(X_train, y_train)\n",
    "print('袋外分数：', rf.oob_score_)\n",
    "model_metrics(rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 特征归一化\n",
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train.values)\n",
    "X_test = std.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 用逻辑回归LR、SVM和决策树DT、随机森林RF和XGBoost等机器学习算法进行模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 利用LR逻辑回归进行模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **from sklearn.linear_model import LogisticRegression**\n",
    "\n",
    "> **lr = LogisticRegression()**\n",
    "\n",
    "> **lr.fit(X_train, y_train)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 利用 SVM 进行模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **from sklearn import svm**\n",
    "\n",
    "> **线性核函数**\n",
    "\n",
    "> **svm_linear = svm.SVC(kernel = 'linear', probability=True).fit(X_train, y_train)**\n",
    "\n",
    "> **多元线性核函数**\n",
    "\n",
    "> **svm_poly = svm.SVC(kernel = 'poly', probability=True).fit(X_train, y_train)**\n",
    "\n",
    "> **径向基函数**\n",
    "\n",
    "> **svm_rbf = svm.SVC(probability=True).fit(X_train, y_train)**\n",
    "\n",
    "> **非线性sigmoid核函数**\n",
    "\n",
    "> **svm_sigmoid = svm.SVC(kernel = 'sigmoid',probability=True).fit(X_train, y_train)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 利用 Decision Tree 进行模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **from sklearn.tree import DecisionTreeClassifier**\n",
    "\n",
    "> **dt = DecisionTreeClassifier(max_depth=4)**\n",
    "\n",
    "> **dt.fit(X_train, y_train)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 利用 Random Forests 进行模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **from sklearn.tree import DecisionTreeClassifier**\n",
    "\n",
    "> **dt = DecisionTreeClassifier(max_depth=5,min_samples_split=50,min_samples_leaf=60, **\n",
    "\n",
    "> **max_features=9, random_state =2018)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 利用 XGBoost 进行模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **from xgboost.sklearn import XGBClassifier**\n",
    "\n",
    "> **xgb = XGBClassifier(learning_rate =0.1, n_estimators=80, max_depth=3, min_child_weight=5,\\\n",
    "                    gamma=0.2, subsample=0.8, colsample_bytree=0.8, reg_alpha=1e-5,\\\n",
    "                    objective= 'binary:logistic', nthread=4,scale_pos_weight=1, seed=27)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C = 0.1, penalty = 'l1')\n",
    "svm_linear = svm.SVC(C = 0.01, kernel = 'linear', probability=True)\n",
    "svm_poly =  svm.SVC(C = 0.01, kernel = 'poly', probability=True)\n",
    "svm_rbf =  svm.SVC(gamma = 0.01, C =0.01 , probability=True)\n",
    "svm_sigmoid =  svm.SVC(C = 0.01, kernel = 'sigmoid',probability=True)\n",
    "dt = DecisionTreeClassifier(max_depth=5,min_samples_split=50,min_samples_leaf=60, max_features=9, random_state =2018)\n",
    "xgb = XGBClassifier(learning_rate =0.1, n_estimators=80, max_depth=3, min_child_weight=5,\\\n",
    "                    gamma=0.2, subsample=0.8, colsample_bytree=0.8, reg_alpha=1e-5,\\\n",
    "                    objective= 'binary:logistic', nthread=4,scale_pos_weight=1, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[准确率] 训练集： 0.7803 测试集： 0.7603\n",
      "[auc值] 训练集： 0.7473 测试集： 0.6938\n"
     ]
    }
   ],
   "source": [
    "dt.fit(X_train, y_train.values)\n",
    "model_metrics(dt, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[准确率] 训练集： 0.8413 测试集： 0.7996\n",
      "[auc值] 训练集： 0.8915 测试集： 0.7972\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train.values)\n",
    "model_metrics(xgb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "> ### Discussion\n",
    "\n",
    "> #### 特征工程的主要流程是什么？\n",
    "\n",
    "> #### IV值的计算、原理及实现\n",
    "\n",
    "> #### 选择重要特征主要有哪些方式？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据挖掘项目流程\n",
    "\n",
    "> ### （1）抽象成数学问题（明确问题）；\n",
    "\n",
    "> ### （2）获取数据；\n",
    "\n",
    "> ### （3）特征预处理与特征选择；\n",
    "\n",
    "> ### （4）训练模型与调优；\n",
    "\n",
    "> ### （5）模型诊断；\n",
    "\n",
    "> ### （6）模型融合（非必须）；\n",
    "\n",
    "> ### （8）上线运行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "> ### 数据准备（费时最多，占比60-70%）\n",
    "> ### 特征提取和特征选择：提取基础特征，进行模型预测。\n",
    "> ### 特征工程的关键在于特征提取 和 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
